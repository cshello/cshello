{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cuda-base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译简化demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "class CudaAutoBuild(object):\n",
    "    def __init__(self, root_dir = \"/tmp/cuda-base\"):\n",
    "        self.root_dir = root_dir \n",
    "        assert root_dir.startswith(\"/tmp\")\n",
    "        os.makedirs(self.root_dir, exist_ok=True)\n",
    "        os.system(f\"rm -rf {os.path.join(self.root_dir, '*')}\")\n",
    "\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __exit__(self, *args, **kws):\n",
    "        pass \n",
    "    \n",
    "    def add_file(self, filename, filestr):\n",
    "        with open(os.path.join(self.root_dir, filename), \"w\") as f:\n",
    "            f.write(f\"{filestr.strip()}\\n\\n\")\n",
    "\n",
    "    def build(self, cmd=None):\n",
    "        if cmd is None:\n",
    "            cmd = \"nvcc hello.cu --generate-code arch=compute_50,code=sm_50 -o hello\"\n",
    "        os.system(f\"cd {self.root_dir} && {cmd}\")\n",
    "    \n",
    "    def exec(self, cmd=None):\n",
    "        if cmd is None:\n",
    "            cmd = \"hello\"\n",
    "        os.system(f\"cd {self.root_dir} && chmod +x {cmd} && ./{cmd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from host!\n",
      "Hello World! from thread [0, 0] From device.\n"
     ]
    }
   ],
   "source": [
    "with CudaAutoBuild() as cab:\n",
    "    cab.add_file(\"hello.cu\", r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void print_HelloWorld(void) {\n",
    "    printf(\"Hello World! from thread [%d, %d] From device.\\n\", threadIdx.x, blockIdx.x);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Hello World from host!\\n\");\n",
    "    print_HelloWorld<<<1, 1>>>();\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}\n",
    "    \"\"\")\n",
    "    cab.build()\n",
    "    cab.exec()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e01-HelloWorld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create hello-world file\n",
    "custr_HelloWorld = r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void print_HelloWorld(void) {\n",
    "    printf(\"Hello World! from thread [%d, %d] From device.\\n\", threadIdx.x, blockIdx.x);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Hello World from host!\\n\");\n",
    "    print_HelloWorld<<<1, 1>>>();\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "    return 0;\n",
    "}\n",
    "    \"\"\"\n",
    "\n",
    "!rm -rf build/*\n",
    "!mkdir build\n",
    "with open(\"build/hello-world.cu\", \"w\") as f:\n",
    "    f.write(custr_HelloWorld)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build\n",
    "!nvcc build/hello-world.cu \\\n",
    "    --generate-code arch=compute_50,code=sm_50 \\\n",
    "    -o build/hello-world\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World from host!\n",
      "Hello World! from thread [0, 0] From device.\n"
     ]
    }
   ],
   "source": [
    "# exec\n",
    "!chmod +x build/hello-world \n",
    "!build/hello-world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e02-add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125 + 236 = 361\n"
     ]
    }
   ],
   "source": [
    "with CudaAutoBuild() as cab:\n",
    "    cab.add_file(\"hello.cu\", r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "\n",
    "// Definition of kernel functin to add two variable\n",
    "__global__ void gpu_add(int d_a, int d_b, int *d_c) {\n",
    "    *d_c = d_a + d_b;\n",
    "}\n",
    "\n",
    "// main function\n",
    "int main() {\n",
    "    // Defining host variable to store answer\n",
    "    int h_a = 125, h_b = 236;\n",
    "    int h_c;\n",
    "\n",
    "    // Defining device pointer\n",
    "    int *d_c;\n",
    "\n",
    "    // Allocating memory for device pointer\n",
    "    cudaMalloc((void**)&d_c, sizeof(int));\n",
    "\n",
    "    // Kernal call\n",
    "    gpu_add<<<1, 1>>>(h_a, h_b, d_c);\n",
    "\n",
    "    // Copy result from device memory to host memory\n",
    "    cudaMemcpy(&h_c, d_c, sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    printf(\"%d + %d = %d\\n\", h_a, h_b, h_c);\n",
    "\n",
    "    // Free up memory\n",
    "    cudaFree(d_c);\n",
    "\n",
    "}\n",
    "    \"\"\")\n",
    "    cab.build()\n",
    "    cab.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## e02-device prop\n",
    "- refer\n",
    "  - https://docs.nvidia.com/cuda/cuda-runtime-api/structcudaDeviceProp.html#structcudaDeviceProp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0 has compute capability 5.0. \n",
      "\t name: NVIDIA GeForce GTX 960M.\n",
      "\t maxThreadsDim: (1024, 1024, 64).\n",
      "\t maxGridSize: (2147483647, 65535, 65535).\n",
      "\t maxThreadsPerBlock: 1024.\n"
     ]
    }
   ],
   "source": [
    "with CudaAutoBuild() as cab:\n",
    "    cab.add_file(\"hello.cu\", r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "// main function\n",
    "int main() {\n",
    "    \n",
    "    int deviceCount = -1;\n",
    "    cudaGetDeviceCount(&deviceCount);\n",
    "    for (int device = 0; device < deviceCount; ++device) {\n",
    "        cudaDeviceProp deviceProp;\n",
    "        cudaGetDeviceProperties(&deviceProp, device);\n",
    "        printf(\"Device %d has compute capability %d.%d. \\n\",\n",
    "            device, deviceProp.major, deviceProp.minor\n",
    "        );\n",
    "        printf(\"\\t name: %s.\\n\", deviceProp.name);\n",
    "        printf(\"\\t maxThreadsDim: (%d, %d, %d).\\n\", deviceProp.maxThreadsDim[0], deviceProp.maxThreadsDim[1], deviceProp.maxThreadsDim[2]);\n",
    "        printf(\"\\t maxGridSize: (%d, %d, %d).\\n\", deviceProp.maxGridSize[0], deviceProp.maxGridSize[1], deviceProp.maxGridSize[2]);\n",
    "        printf(\"\\t maxThreadsPerBlock: %d.\\n\", deviceProp.maxThreadsPerBlock);\n",
    "    }\n",
    "    return 0;    \n",
    "\n",
    "}\n",
    "    \"\"\")\n",
    "    cab.build()\n",
    "    cab.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add-mul\n",
    "计算  \n",
    "$y = a - \\dfrac{b}{2} + c^2 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda \n",
    "with CudaAutoBuild() as cab:\n",
    "    cab.add_file(\"hello.cu\", r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "// Definition of kernel functin to add two variable\n",
    "// y = a - b / 2 + c ** 2\n",
    "__global__ void\n",
    "arr_add(size_t n, float *d_a, float *d_b, float *d_c, float *d_y) {\n",
    "    size_t tid = blockIdx.x;\n",
    "    if (tid < n) {\n",
    "        d_y[tid] = d_a[tid] - d_b[tid] / 2 + d_c[tid] * d_c[tid];\n",
    "//        printf(\"idx a b c y: %05ld, %f, %f, %f, %f\\n\", tid, d_a[tid], d_b[tid],\n",
    "//               d_c[tid], d_y[tid]);\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "// main function\n",
    "int main() {\n",
    "    size_t n = 100000;\n",
    "    float h_a[n], h_b[n], h_c[n], h_y[n];\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        h_a[i] = (float) i;\n",
    "        h_b[i] = (float) i;\n",
    "        h_c[i] = (float) i;\n",
    "        h_y[i] = 0;\n",
    "    }\n",
    "\n",
    "    float *d_a, *d_b, *d_c, *d_y;\n",
    "\n",
    "    // Allocating memory\n",
    "    cudaMalloc((void **) &d_a, n * sizeof(float));\n",
    "    cudaMalloc((void **) &d_b, n * sizeof(float));\n",
    "    cudaMalloc((void **) &d_c, n * sizeof(float));\n",
    "    cudaMalloc((void **) &d_y, n * sizeof(float));\n",
    "\n",
    "    // Copy data to device\n",
    "    cudaMemcpy(d_a, h_a, n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_c, h_c, n * sizeof(float), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Kernel call\n",
    "    arr_add<<<n, 1>>>(n, d_a, d_b, d_c, d_y);\n",
    "\n",
    "    // Copy result\n",
    "    cudaMemcpy(h_y, d_y, n * sizeof(float), cudaMemcpyDeviceToHost);\n",
    "    \n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    float sum = 0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        sum += h_y[i];\n",
    "    }\n",
    "    // printf(\"sum: %f, \", sum);\n",
    "    \n",
    "    // Free\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    cudaFree(d_y);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "    \"\"\")\n",
    "    cab.build()\n",
    "    cab.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 ms ± 2.44 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit  \n",
    "!/tmp/cuda-base/hello "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpp\n",
    "with CudaAutoBuild() as cab:\n",
    "    cab.add_file(\"hello.cu\", r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "// Main Program\n",
    "// y = a - b / 2 + c ** 2\n",
    "void arr_add(size_t n, const float *a, const float *b, const float *c, float *y) {\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        y[i] = a[i] - b[i] / 2 + c[i] * c[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main() {\n",
    "    size_t n = 100000;\n",
    "    float a[n], b[n], c[n], y[n];\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        a[i] = (float)i;\n",
    "        b[i] = (float)i;\n",
    "        c[i] = (float)i;\n",
    "        y[i] = 0;\n",
    "    }\n",
    "\n",
    "    arr_add(n, a, b, c, y);\n",
    "    float sum = 0;\n",
    "    for (size_t i = 0; i < n; ++i) {\n",
    "        sum += y[i];\n",
    "    }\n",
    "    // printf(\"sum: %f, \", sum);\n",
    "}\n",
    "    \"\"\")\n",
    "    cab.build()\n",
    "    cab.exec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 ms ± 854 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit  \n",
    "!/tmp/cuda-base/hello "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### benchmark n 100000  \n",
    "```txt\n",
    "-------------------------------------------------------------\n",
    "Benchmark                   Time             CPU   Iterations\n",
    "-------------------------------------------------------------\n",
    "bm_arr_add_cpu/1       351769 ns       351759 ns         1905\n",
    "bm_arr_add_cpu/10     3320200 ns      3320090 ns          209\n",
    "bm_arr_add_cpu/100   33445583 ns     33444053 ns           21\n",
    "\n",
    "\n",
    "-------------------------------------------------------------\n",
    "Benchmark                   Time             CPU   Iterations\n",
    "-------------------------------------------------------------\n",
    "bm_arr_add_gpu/1       502368 ns       502253 ns        10000\n",
    "bm_arr_add_gpu/10     5023164 ns      5022271 ns         1000\n",
    "bm_arr_add_gpu/100   50218850 ns     50204298 ns          100\n",
    "\n",
    "\n",
    "----------------------------------------------------------------\n",
    "Benchmark                      Time             CPU   Iterations\n",
    "----------------------------------------------------------------\n",
    "bm_arr_add_cpu/100         18050 ns        18046 ns        36805\n",
    "bm_arr_add_cpu/1000      1690554 ns      1690532 ns          429\n",
    "bm_arr_add_cpu/10000   177923426 ns    177912452 ns            4\n",
    "bm_arr_add_cpu/100000 1.6662e+10 ns   1.6662e+10 ns            1\n",
    "\n",
    "----------------------------------------------------------------\n",
    "Benchmark                      Time             CPU   Iterations\n",
    "----------------------------------------------------------------\n",
    "bm_arr_add_gpu/100        287895 ns       287858 ns         2302\n",
    "bm_arr_add_gpu/1000      5723494 ns      5723163 ns          138\n",
    "bm_arr_add_gpu/10000   291581341 ns    291429314 ns            3\n",
    "bm_arr_add_gpu/100000 2.7557e+10 ns   2.7556e+10 ns            1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量点乘  - todo\n",
    "计算两个向量的点乘， 点乘的公式如下，第1条公式是三维向量，第2条是n维向量\n",
    "$$A*B = (x_1, x_2, x_3) * (y_1, y_2, y_3) = x_1 * y_1 + x_2 * y_2 + x_3 * y_3$$\n",
    "$$\\mathbf{a}*\\mathbf{b} = \\sum_{0}^{n}a_i * b_i$$\n",
    "\n",
    "\n",
    "向量点乘用的那些方法：\n",
    "1. 用到了cuda的__shared__变量的特性，在block块中，thread线程共享__shared__变量空间。\n",
    "2. 用到了__syncthreads方法，用于块线程同步。该方法一般不放于if判断中，防止线程一直处于等待同步状态。\n",
    "2. 用到了归约算法，\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bid: 2, tid: 0, idx: 16, \t16 * 2 = 32, \n",
      "bid: 2, tid: 1, idx: 17, \t17 * 2 = 34, \n",
      "bid: 2, tid: 2, idx: 18, \t18 * 2 = 36, \n",
      "bid: 2, tid: 3, idx: 19, \t19 * 2 = 38, \n",
      "bid: 2, tid: 4, idx: 20, \t20 * 2 = 40, \n",
      "bid: 2, tid: 5, idx: 21, \t21 * 2 = 42, \n",
      "bid: 2, tid: 6, idx: 22, \t22 * 2 = 44, \n",
      "bid: 2, tid: 7, idx: 23, \t23 * 2 = 46, \n",
      "bid: 0, tid: 0, idx: 0, \t0 * 2 = 0, \n",
      "bid: 0, tid: 1, idx: 1, \t1 * 2 = 2, \n",
      "bid: 0, tid: 2, idx: 2, \t2 * 2 = 4, \n",
      "bid: 0, tid: 3, idx: 3, \t3 * 2 = 6, \n",
      "bid: 0, tid: 4, idx: 4, \t4 * 2 = 8, \n",
      "bid: 0, tid: 5, idx: 5, \t5 * 2 = 10, \n",
      "bid: 0, tid: 6, idx: 6, \t6 * 2 = 12, \n",
      "bid: 0, tid: 7, idx: 7, \t7 * 2 = 14, \n",
      "bid: 1, tid: 0, idx: 8, \t8 * 2 = 16, \n",
      "bid: 1, tid: 1, idx: 9, \t9 * 2 = 18, \n",
      "bid: 1, tid: 2, idx: 10, \t10 * 2 = 20, \n",
      "bid: 1, tid: 3, idx: 11, \t11 * 2 = 22, \n",
      "bid: 1, tid: 4, idx: 12, \t12 * 2 = 24, \n",
      "bid: 1, tid: 5, idx: 13, \t13 * 2 = 26, \n",
      "bid: 1, tid: 6, idx: 14, \t14 * 2 = 28, \n",
      "bid: 1, tid: 7, idx: 15, \t15 * 2 = 30, \n",
      "vec: 0, 14, \n",
      "vec: 32, 46, \n",
      "vec: 16, 30, \n",
      "blockIdx.x=0, blockIdx.x=2, blockIdx.x=1, 56, 184, 312, \n",
      "Result from gpu device: 552, \n",
      "Result from cpu host: 552, \n"
     ]
    }
   ],
   "source": [
    "with CudaAutoBuild() as cab:\n",
    "    cab.add_file(\"hello.cu\", r\"\"\"\n",
    "#include <stdio.h>\n",
    "\n",
    "#define threadsPerBlock 8\n",
    "#define N (threadsPerBlock * 3)\n",
    "\n",
    "\n",
    "__global__ void vec_dot(const int *a, const int *b, int *c) {\n",
    "\n",
    "    __shared__ int vec[threadsPerBlock];\n",
    "\n",
    "    size_t idx = threadIdx.x + blockDim.x * blockIdx.x;\n",
    "    size_t tid = threadIdx.x;\n",
    "\n",
    "    if (idx<N) {\n",
    "        vec[tid] = a[idx] * b[idx];\n",
    "        printf(\"bid: %d, tid: %d, idx: %ld, \\t%d * %d = %d, \\n\", blockIdx.x, threadIdx.x, idx, a[idx], b[idx], vec[tid]);\n",
    "    }\n",
    "\n",
    "    __syncthreads();\n",
    "\n",
    "    if (tid == 0) {\n",
    "        printf(\"vec: %d, %d, \\n\", vec[0], vec[threadsPerBlock-1]);\n",
    "    }\n",
    "\n",
    "    size_t size = threadsPerBlock / 2;\n",
    "\n",
    "    while (size > 0) {\n",
    "\n",
    "        if (tid < size) {\n",
    "            vec[tid] = vec[tid] + vec[tid + size];\n",
    "        }\n",
    "        __syncthreads();\n",
    "        size /= 2;\n",
    "    }\n",
    "\n",
    "    if (tid == 0) {\n",
    "        c[blockIdx.x] = vec[0];\n",
    "        printf(\"blockIdx.x=%d, \", blockIdx.x);\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "\n",
    "    size_t blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    int h_a[N], h_b[N], h_c[blocksPerGrid];\n",
    "\n",
    "    int *d_a, *d_b, *d_c;\n",
    "\n",
    "    // assigned\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        h_a[i] = i;\n",
    "        h_b[i] = 2;\n",
    "    }\n",
    "\n",
    "    // Malloc\n",
    "    cudaMalloc((void **) &d_a, N * sizeof(int));\n",
    "    cudaMalloc((void **) &d_b, N * sizeof(int));\n",
    "    cudaMalloc((void **) &d_c, blocksPerGrid * sizeof(int));\n",
    "\n",
    "    // Copy data from host to device\n",
    "    cudaMemcpy(d_a, h_a, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, N * sizeof(int), cudaMemcpyHostToDevice);\n",
    "\n",
    "    // Run kernel\n",
    "    vec_dot<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c);\n",
    "\n",
    "    // Copy data from device to host\n",
    "    cudaMemcpy(h_c, d_c, blocksPerGrid * sizeof(int), cudaMemcpyDeviceToHost);\n",
    "\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "    // sum\n",
    "    printf(\"%d, \", h_c[0]);\n",
    "    for (int i = 1; i < blocksPerGrid; ++i) {\n",
    "        h_c[0] += h_c[i];\n",
    "        printf(\"%d, \", h_c[i]);\n",
    "    }\n",
    "    printf(\"\\n\");\n",
    "    printf(\"Result from gpu device: %d, \\n\", h_c[0]);\n",
    "    printf(\"Result from cpu host: %d, \\n\", N * (N - 1));\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "    \"\"\")\n",
    "    cab.build()\n",
    "    cab.exec()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵乘法  --todo  \n",
    "\n",
    "$$ \n",
    "M =\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "1 & 0 \\\\\n",
    "0 & 1\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc-autonumbering": true,
  "vscode": {
   "interpreter": {
    "hash": "d4238c57844cc908b76449bc4ddf9899590ca8e7952f36c82afaad1c379a56db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
